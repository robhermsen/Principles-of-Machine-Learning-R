{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Regression\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab you will apply regression to some realistic data. In this lab you will work with the automotive price dataset. Your goal is to construct a linear regression model to predict the price of automobiles from their characteristics. \n",
    "\n",
    "In this lab will learn to:\n",
    "\n",
    "1. Use categorical data with R machine learning models. \n",
    "2. Apply transformations to features and labels to improve model performance. \n",
    "3. Compare regression models to improve model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "As a first, step you will load the dataset into the notebook environment. \n",
    "\n",
    "First, execute the code in the cell below to load  the packages you will need to run the rest of this notebook. \n",
    "\n",
    "> **Note:** If you are running in Azure Notebooks, make sure that you run the code in the `setup.ipynb` notebook at the start of you session to ensure your environment is correctly configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages ggplot2, repr, dplyr, and caret\n",
    "\n",
    "# Set the initial plot area dimensions\n",
    "options(repr.plot.width=4, repr.plot.height=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below loads the dataset which was prepared from the Data Preparation lab. Execute this code and ensure that the expected columns are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file \"Auto_Prices_Preped.csv\" (the file you stored in a prior notebook) and assign it to auto_prices\n",
    "\n",
    "# inspect the name of auto_prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both the label, `price` and the logrithmically transformed versions are included. \n",
    "\n",
    "As a next step, execute the code in the cell below to display and examine the first few rows of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the auto_prices data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are both numeric and categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n",
    "You must now create randomly sampled training and test data sets. The `createDataPartition` function from the R caret package is used  to create indices for the training data sample. In this case 75% of the data will be used  for training the model. Since this data set is small only 48 cases will be included in the test dataset. Execute this code and note the dimensions of the resulting data frame.\n",
    "\n",
    "****\n",
    "**Note** The `createDataPartition` function allows you to balance categorical cases, creating **stratified sub-samples**. For example, choosing `fuel.type` as the stratification creates sub-samples with equal numbers of cars with each fuel type. \n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it repeatable \n",
    "set.seed(1955)\n",
    "\n",
    "## Randomly sample cases to create independent training and test data\n",
    "partition = createDataPartition(auto_prices[,'fuel.type'], times = 1, p = 0.75, list = FALSE)\n",
    "\n",
    "# Create the training sample\n",
    "training = auto_prices[partition,] \n",
    "\n",
    "# check the dimensions of the training data\n",
    "\n",
    "# create the test sample\n",
    "test = auto_prices[-partition,] \n",
    "\n",
    "# check the dimensions of the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale numeric features\n",
    "\n",
    "Numeric features must be rescaled so they have a similar range of values. Rescaling prevents features from having an undue influence on model training simply because then have a larger range of numeric variables. \n",
    "\n",
    "The code in the cell below uses the `preProcess` function from the caret function. The processing is as follows:\n",
    "1. The preprocessing model object is computed. In this case the processing includes centering and scaling the numeric feature. Notice that this model is fit only to the training data.\n",
    "2. The scaling is applied both the test and training partitions.\n",
    "\n",
    "Execute the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = c('curb.weight', 'horsepower', 'city.mpg')\n",
    "preProcValues <- preProcess(training[,num_cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "training[,num_cols] = predict(preProcValues, training[,num_cols])\n",
    "test[,num_cols] = predict(preProcValues, test[,num_cols])\n",
    "head(training[,num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three numeric features are now scaled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the linear regression model\n",
    "\n",
    "With data prepared and split into training and test subsets, you will now compute the linear regression model. There are 28 features, so the model will require at least 28 coefficients. The equation for such a **multiple regression** problem can be written as:\n",
    "\n",
    "$$\\hat{y} = f(\\vec{x}) = \\vec{\\beta} \\cdot \\vec{x} + b\\\\ = \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n + b$$  \n",
    "where;  \n",
    "$\\hat{y}$ are the predicted values or scores,   \n",
    "$\\vec{x}$ is the vector of feature values with components $\\{ x_1, x_2, \\cdots, x_n$,  \n",
    "$\\vec{\\beta}$ is vector of model coefficients with components $\\{ \\beta_1, \\beta_2, \\cdots, \\beta_n$,  \n",
    "$b$ is the intercept term, if there is one.\n",
    "\n",
    "You can think of the linear regression function $f(\\vec{x})$ as the dot product between the beta vector $\\vec{\\beta}$ and the feature vector $\\vec{x}$, plus the intercept term $b$.\n",
    "\n",
    "In R models are defined by an equation using the $\\sim$ symbol to mean modeled by. In summary, the variable to be modeled is always on the left. The features are listed on the right. This basic scheme can be written as shown here. \n",
    "\n",
    "$$label \\sim features$$\n",
    "\n",
    "Categorical and numerical features can be combined in the model formula. Features not specified in the formula are ignored.\n",
    "\n",
    "The code in the cell below uses the R `lm` function to compute the model coefficients and create a model object.  Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define and fit the linear regression model \"lin_mod\" with the lm() function we have seen before.\n",
    "# We are training a model to predict log_price, by using\n",
    "# curb.weight + horsepower + city.mpg + fuel.type + aspiration + body.style + drive.wheels + num.of.cylinders\n",
    "# use your training data to train the model with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been fit to the training data. Execute the code in the cell below to examine the value of the intercept term and coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lin_mod)$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interpret these coefficients as follows:\n",
    "1. The intercept is the mean of the (log) price with respect to the (scaled) features. \n",
    "2. The coefficients numeric features are the change in the (log) price for a unit change in the (scaled) feature.\n",
    "3. The coefficients of the categorical features are a bit harder to understand. R uses a technique known at the **method of contrasts**. The intercept is computed using one, arbitrarily chosen, category. The coefficients for other categories are the differences, or contrasts, with the intercept term for each category. This means that there are $n-1$ coefficients for each categorical feature with $n$ categories. \n",
    "\n",
    "Now, answer **Question 1** on the course page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "You will now use the test dataset to evaluate the performance of the regression model. As a first step, execute the code in the cell below to compute and display various performance metrics and examine the results. Then, answer **Question 2** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics = function(lin_mod, df, score, label){\n",
    "    resids = df[,label] - score\n",
    "    resids2 = resids**2\n",
    "    N = length(score)\n",
    "    r2 = as.character(round(summary(lin_mod)$r.squared, 4))\n",
    "    adj_r2 = as.character(round(summary(lin_mod)$adj.r.squared, 4))\n",
    "    cat(paste('Mean Square Error      = ', as.character(round(sum(resids2)/N, 4)), '\\n'))\n",
    "    cat(paste('Root Mean Square Error = ', as.character(round(sqrt(sum(resids2)/N), 4)), '\\n'))\n",
    "    cat(paste('Mean Absolute Error    = ', as.character(round(sum(abs(resids))/N, 4)), '\\n'))\n",
    "    cat(paste('Median Absolute Error  = ', as.character(round(median(abs(resids)), 4)), '\\n'))\n",
    "    cat(paste('R^2                    = ', r2, '\\n'))\n",
    "    cat(paste('Adjusted R^2           = ', adj_r2, '\\n'))\n",
    "}\n",
    "\n",
    "score = predict(lin_mod, newdata = test)\n",
    "print_metrics(lin_mod, test, score, label = 'log_price')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, these metrics look promising. The RMSE, MAE and median absolute error are all small and in a similar range. However, notice that the $R^2$ and $R^2_{adj}$ are somewhat different. This model has a large number of parameters compared to the number of cases available. This result indicates that the model may be over-fit and might not generalize well. \n",
    "\n",
    "To continue the evaluation of the model performance, execute the code in the cell below to display a histogram of the residuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist_resids = function(df, score, label, bins = 10){\n",
    "    options(repr.plot.width=4, repr.plot.height=3) # Set the initial plot area dimensions\n",
    "    df$resids = df[,label] - score\n",
    "    bw = (max(df$resids) - min(df$resids))/(bins + 1)\n",
    "    ggplot(df, aes(resids)) + \n",
    "       geom_histogram(binwidth = bw, aes(y=..density..), alpha = 0.5) +\n",
    "       geom_density(aes(y=..density..), color = 'blue') +\n",
    "       xlab('Residual value') + ggtitle('Histogram of residuals')\n",
    "}\n",
    "\n",
    "hist_resids(test, score, label = 'log_price')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the residuals are in a small range. However, there is some noticeable skew in the distribution, including an outlier. \n",
    "\n",
    "Next, execute the code in the cell below to display the Q-Q Normal plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_qq = function(df, score, label){\n",
    "    options(repr.plot.width=4, repr.plot.height=3.5) # Set the initial plot area dimensions\n",
    "    df$resids = df[,label] - score\n",
    "    ggplot() + \n",
    "    geom_qq(data = df, aes(sample = resids)) + \n",
    "    ylab('Quantiles of residuals') + xlab('Quantiles of standard Normal') +\n",
    "    ggtitle('QQ plot of residual values')\n",
    "}\n",
    "\n",
    "resids_qq(test, score, label = 'log_price') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the histogram, the Q-Q Normal plot indicates the residuals are close to Normally distributed, show some skew (deviation from the straight line). This is particularly for large positive residuals. \n",
    "\n",
    "There is one more diagnostic plot. Execute the code in the cell below to display the plot of residuals vs. predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_plot = function(df, score, label){\n",
    "    df$score = score\n",
    "    df$resids = df[,label] - score\n",
    "    ggplot(df, aes(score, resids)) + \n",
    "    geom_point() + \n",
    "    ggtitle('Residuals vs. Predicted Values') +\n",
    "    xlab('Predicted values') + ylab('Residuals')\n",
    "}\n",
    "\n",
    "resid_plot(test, score, label = 'log_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot looks reasonable. The residual values appear to have a fairly constant dispersion as the predicted value changes. A few large residuals are noticeable, particularly on the positive side.\n",
    "\n",
    "But, wait! This residual plot is for the log of the auto price. What does the plot look like when transformed to real prices? Execute the code in the cell below to find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_untransform = exp(score)\n",
    "resid_plot(test, score_untransform, label = 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the untransformed residuals show a definite trend. The dispersion of the residuals has a cone-like pattern increasing to the right. The regression model seems to do a good job of predicting the price of low cost cars, but becomes progressively worse as the price of the car increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson you have done the following in the process of constructing and evaluating a multiple linear regression model:   \n",
    "1. Transformed the label value to make it more symmetric and closer to a Normal distribution.\n",
    "2. Aggregated categories of a categorical variable to improve the statistical representation. \n",
    "3. Scaled the numeric features. \n",
    "5. Fit the linear regression model using the `lm` function. A categorical feature with $n$ categories produces $n-1$ model coefficients.  \n",
    "6. Evaluated the performance of the model using both numeric and graphical methods. \n",
    "\n",
    "It is clear from the outcome of the performance evaluation that this model needs to be improved. As it is, the model shows poor generalization for high cost autos. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
